import { Camelize } from '../constants';
import { Component as GraphConfigComponent, TextGenerationConfig } from '../graph_config_schema';
import { AbstractComponent, AbstractComponentProps } from './AbstractComponent';
/**
 * Configuration interface for RemoteLLMComponent creation.
 */
interface RemoteLLMComponentProps extends AbstractComponentProps {
    /** LLM provider (e.g., 'openai', 'anthropic', 'inworld') */
    provider?: string;
    /** Model name to use. Model name is specific to the selected provider */
    modelName?: string;
    /** Default text generation configuration */
    defaultConfig?: Camelize<TextGenerationConfig>;
}
/**
 * Remote LLM component for text generation services.
 * This component provides access to external LLM providers like OpenAI, Anthropic, or Inworld.
 * It handles authentication and default configuration for text generation.
 *
 * @example
 * ```typescript
 * const llmComponent = new RemoteLLMComponent({
 *   id: 'my-llm-component',
 *   provider: 'openai',
 *   modelName: 'gpt-4o-mini',
 *   defaultConfig: {
 *     temperature: 0.7,
 *     maxNewTokens: 1000
 *   }
 * });
 * ```
 */
export declare class RemoteLLMComponent extends AbstractComponent {
    private provider;
    private modelName;
    private defaultConfig;
    /**
     * Creates a new RemoteLLMComponent instance.
     *
     * @param props - Configuration for the remote LLM component
     */
    constructor(props?: RemoteLLMComponentProps);
    /**
     * Converts the remote LLM component to a graph configuration component.
     *
     * @returns The configured a remote LLM component for graph execution
     */
    protected toGraphConfigComponent(): GraphConfigComponent;
}
export {};
