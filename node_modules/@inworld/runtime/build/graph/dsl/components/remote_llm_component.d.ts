import { Camelize } from '../constants';
import { Component as GraphConfigComponent, TextGenerationConfig } from '../graph_config_schema';
import { AbstractComponent, AbstractComponentProps } from './abstract_component';
/**
 * @typedef {Object} RemoteLLMComponentProps
 * @property {string} [id] - Optional explicit component identifier.
 * @property {string} [provider] - LLM provider (e.g., 'openai', 'anthropic', 'inworld').
 * @property {string} [modelName] - Provider-specific model name (e.g., 'gpt-4o-mini').
 * @property {import('../graph_config_schema').TextGenerationConfig} [defaultConfig] - Default text generation config (camelCase allowed).
 *
 * Configuration interface for `RemoteLLMComponent` creation.
 *
 * @remarks
 * - If `provider` is omitted, a default provider is used.
 * - If `modelName` is omitted, a provider-specific default model is used.
 * - `defaultConfig` follows the `TextGenerationConfig` shape but accepts camelCase keys.
 */
interface RemoteLLMComponentProps extends AbstractComponentProps {
    /** LLM provider (e.g., 'openai', 'anthropic', 'inworld') */
    provider?: string;
    /** Model name to use. Model name is specific to the selected provider */
    modelName?: string;
    /** Default text generation configuration */
    defaultConfig?: Camelize<TextGenerationConfig>;
}
/**
 * Remote LLM component for text generation services.
 * This component provides access to external LLM providers like OpenAI, Anthropic, or Inworld.
 * It sets defaults for provider/model and carries default text generation config.
 *
 * @remarks
 * API key injection is handled by the graph builder at assembly time. You do not
 * need to include secrets in this component definition.
 *
 * @example
 * ```typescript
 * const llmComponent = new RemoteLLMComponent({
 *   id: 'my-llm-component',
 *   provider: 'openai',
 *   modelName: 'gpt-4o-mini',
 *   defaultConfig: {
 *     temperature: 0.7,
 *     maxNewTokens: 1000
 *   }
 * });
 * ```
 */
export declare class RemoteLLMComponent extends AbstractComponent {
    private provider;
    private modelName;
    private defaultConfig;
    /**
     * Creates a new `RemoteLLMComponent` instance.
     *
     * Defaults to a provider and model when omitted, and accepts a camelCased
     * `defaultConfig` that will be converted to snake_case for the runtime.
     *
     * @param {Object} [props] - Configuration for the remote LLM component
     * @param {string} [props.id] - Optional explicit component identifier
     * @param {string} [props.provider] - LLM provider (e.g., 'openai', 'anthropic', 'inworld')
     * @param {string} [props.modelName] - Provider-specific model name (e.g., 'gpt-4o-mini')
     * @param {import('../graph_config_schema').TextGenerationConfig} [props.defaultConfig] - Default text generation config (camelCase required)
     */
    constructor(props?: RemoteLLMComponentProps);
    /**
     * Converts the remote LLM component to a graph configuration component.
     *
     * @returns The configured remote LLM component for graph execution
     */
    protected toGraphConfigComponent(): GraphConfigComponent;
}
export {};
