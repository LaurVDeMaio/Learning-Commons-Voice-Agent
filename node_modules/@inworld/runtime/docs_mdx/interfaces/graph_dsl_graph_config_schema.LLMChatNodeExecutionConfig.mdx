---
---


<style dangerouslySetInnerHTML={{ __html: `
  .mintlify-table {
    width: 100%;
    border-collapse: collapse;
    margin: 1.5rem 0;
    font-size: 0.9rem;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    border-radius: 4px;
    overflow: hidden;
  }
  
  .mintlify-table th {
    background-color: #f8fafc;
    color: #475569;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    padding: 0.75rem 1rem;
    border-bottom: 2px solid #e2e8f0;
    text-align: left;
  }
  
  .mintlify-table td {
    padding: 0.75rem 1rem;
    border-bottom: 1px solid #e2e8f0;
    color: #334155;
  }
  
  .mintlify-table tr:nth-child(even) {
    background-color: #f8fafc;
  }
  
  .mintlify-table tr:last-child td {
    border-bottom: none;
  }
  
  .mintlify-table tr:hover {
    background-color: #f1f5f9;
  }
` }} />


[@inworld/runtime](/)




Preparing search index...

[](/interfaces)

  * [graph/dsl/graph_config_schema](/modules/graph_dsl_graph_config_schema)
  * [LLMChatNodeExecutionConfig]()



# Interface LLMChatNodeExecutionConfig

Configuration for executing LLM chat nodes

This interface was referenced by `InworldBasicConfigurationSchema`'s JSON-Schema via the `definition` "LLMChatNodeExecutionConfig".

interface LLMChatNodeExecutionConfig {  
llm_component_id: string;  
report_to_client?: string | boolean;  
stream?: string | boolean;  
}

##### Index

### Properties

llm_component_id report_to_client? stream?

## Properties

### llm_component_id

llm_component_id: string

ID of the LLM component to use

### `Optional`report_to_client

report_to_client?: string | boolean

Whether to report node execution result to the client

### `Optional`stream

stream?: string | boolean

Whether to stream the response

### Settings

Member Visibility

  * Protected
  * Inherited
  * External



ThemeOSLightDark

### On This Page

Properties

llm_component_idreport_to_clientstream

[@inworld/runtime](/)

  * Loading...



Generated using [TypeDoc](https://typedoc.org/)
