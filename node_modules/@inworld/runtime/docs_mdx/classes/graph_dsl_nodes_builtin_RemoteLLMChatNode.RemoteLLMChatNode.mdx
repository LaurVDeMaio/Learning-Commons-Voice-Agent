---
---


<style dangerouslySetInnerHTML={{ __html: `
  .mintlify-table {
    width: 100%;
    border-collapse: collapse;
    margin: 1.5rem 0;
    font-size: 0.9rem;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    border-radius: 4px;
    overflow: hidden;
  }
  
  .mintlify-table th {
    background-color: #f8fafc;
    color: #475569;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    padding: 0.75rem 1rem;
    border-bottom: 2px solid #e2e8f0;
    text-align: left;
  }
  
  .mintlify-table td {
    padding: 0.75rem 1rem;
    border-bottom: 1px solid #e2e8f0;
    color: #334155;
  }
  
  .mintlify-table tr:nth-child(even) {
    background-color: #f8fafc;
  }
  
  .mintlify-table tr:last-child td {
    border-bottom: none;
  }
  
  .mintlify-table tr:hover {
    background-color: #f1f5f9;
  }
` }} />


[@inworld/runtime](/)




Preparing search index...

[](/classes)

  * [graph/dsl/nodes/builtin/RemoteLLMChatNode](/modules/graph_dsl_nodes_builtin_RemoteLLMChatNode)
  * [RemoteLLMChatNode]()



# Class RemoteLLMChatNode

Remote LLM chat node. You can either use a pre-configured LLM component that could be reused across multiple nodes or provide the LLM provider and model name and the node will create a new component for you.

#### Input

[LLMChatRequestData](./common_data_types_external_llm_chat_request_data.LLMChatRequestData) \- The data type that LLMChatNode accepts as input

#### Output

[LLMChatResponseData](./common_data_types_external_llm_chat_response_data.LLMChatResponseData) \- The data type that LLMChatNode accepts as output

#### Example


```
// Using LLM provider configurationconst llmNode = new RemoteLLMChatNode(&#123;  id: 'my-llm-node',  provider: 'openai',  modelName: 'gpt-4o-mini',  stream: true&#125;);// Using existing LLM componentconst llmNodeWithComponent = new RemoteLLMChatNode(&#123;  id: 'my-llm-node',  llmComponent: existingLLMComponent&#125;);// Using default settingsconst defaultLlmNode = new RemoteLLMChatNode();

```


##### Index

### Constructors

constructor

## Constructors

### constructor

  * new RemoteLLMChatNode(  
props?: RemoteLLMChatNodeProps | RemoteLLMChatNodeWithLLMComponentProps,  
): [RemoteLLMChatNode]()

Creates a new RemoteLLMChatNode instance.

#### Parameters

    * props: RemoteLLMChatNodeProps | RemoteLLMChatNodeWithLLMComponentProps = {}

Optional configuration for the LLM chat node. Can specify either LLM provider settings or reference an existing LLM component, but not both. If not provided, uses default settings.

#### Returns [RemoteLLMChatNode]()

Overrides AbstractNode.constructor




### Settings

Member Visibility

  * Protected
  * Inherited
  * External



ThemeOSLightDark

### On This Page

Constructors

constructor

[@inworld/runtime](/)

  * Loading...



Generated using [TypeDoc](https://typedoc.org/)
