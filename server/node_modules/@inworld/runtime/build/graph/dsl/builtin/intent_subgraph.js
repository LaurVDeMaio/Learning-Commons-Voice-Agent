"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.intentSubgraph = void 0;
const intentSubgraph = (parameters) => {
    return {
        id: 'intent_subgraph',
        nodes: [
            {
                id: 'input_node',
                type: 'ProxyNode',
            },
            {
                id: 'strict_match_node',
                type: 'StrictMatchNode',
                creation_config: {
                    type: 'StrictMatchNodeCreationConfig',
                    properties: {
                        intents: parameters.intents,
                    },
                },
            },
            {
                id: 'embedder_match_node',
                type: 'EmbedderMatchNode',
                creation_config: {
                    type: 'EmbedderMatchNodeCreationConfig',
                    properties: {
                        intents: parameters.intents,
                        embedder_component_id: parameters.embedderComponentId,
                    },
                },
                execution_config: {
                    type: 'EmbedderMatchNodeExecutionConfig',
                    properties: {
                        similarity_threshold: parameters.similarityThreshold,
                    },
                },
            },
            {
                id: 'llm_prompt_vars_node',
                type: 'LLMPromptVariablesBuilderNode',
                creation_config: {
                    type: 'LLMPromptVariablesBuilderNodeCreationConfig',
                    properties: {
                        intents: parameters.intents,
                    },
                },
                execution_config: {
                    type: 'LLMPromptVariablesBuilderNodeExecutionConfig',
                    properties: {
                        max_intents_for_llm: parameters.maxIntentsForLLM,
                        max_phrases_per_intent: parameters.maxPhrasesPerIntent,
                        embedding_similarity_threshold: parameters.embeddingSimilarityThreshold,
                    },
                },
            },
            {
                id: 'llm_request_builder_node',
                type: 'LLMChatRequestBuilderNode',
                execution_config: {
                    type: 'LLMChatRequestBuilderNodeExecutionConfig',
                    properties: {
                        messages: [
                            {
                                role: 'user',
                                content: {
                                    type: 'template',
                                    template: parameters.promptTemplate,
                                },
                            },
                        ],
                    },
                },
            },
            {
                id: 'llm_chat_node',
                type: 'LLMChatNode',
                execution_config: {
                    type: 'LLMChatNodeExecutionConfig',
                    properties: {
                        llm_component_id: parameters.llmComponentId,
                        text_generation_config: parameters.textGenerationConfig,
                    },
                },
            },
            {
                id: 'llm_response_parser_node',
                type: 'LLMResponseParserNode',
            },
            {
                id: 'top_n_filter_node',
                type: 'TopNFilterNode',
                execution_config: {
                    type: 'TopNFilterNodeExecutionConfig',
                    properties: {
                        top_n_intents: parameters.topNIntents,
                    },
                },
            },
        ],
        edges: [
            { from_node: 'input_node', to_node: 'strict_match_node' },
            { from_node: 'input_node', to_node: 'embedder_match_node' },
            { from_node: 'input_node', to_node: 'llm_prompt_vars_node' },
            {
                from_node: 'strict_match_node',
                to_node: 'top_n_filter_node',
                condition_expression: `size(input.intent_matches) >= ${parameters.topNIntents}`,
                optional: true,
            },
            {
                from_node: 'strict_match_node',
                to_node: 'embedder_match_node',
                condition_expression: `size(input.intent_matches) <  ${parameters.topNIntents}`,
            },
            {
                from_node: 'embedder_match_node',
                to_node: 'top_n_filter_node',
                condition_expression: `size(input.intent_matches.filter(x, x.score >= ${parameters.embeddingSimilarityThreshold})) >= ${parameters.topNIntents}`,
                optional: true,
            },
            {
                from_node: 'embedder_match_node',
                to_node: 'llm_prompt_vars_node',
                condition_expression: `size(input.intent_matches.filter(x, x.score >= ${parameters.embeddingSimilarityThreshold})) < ${parameters.topNIntents}`,
            },
            {
                from_node: 'llm_prompt_vars_node',
                to_node: 'llm_request_builder_node',
            },
            { from_node: 'llm_request_builder_node', to_node: 'llm_chat_node' },
            { from_node: 'llm_chat_node', to_node: 'llm_response_parser_node' },
            {
                from_node: 'llm_prompt_vars_node',
                to_node: 'llm_response_parser_node',
            },
            {
                from_node: 'llm_response_parser_node',
                to_node: 'top_n_filter_node',
                optional: true,
            },
        ],
        start_nodes: ['input_node'],
        end_nodes: ['top_n_filter_node'],
    };
};
exports.intentSubgraph = intentSubgraph;
